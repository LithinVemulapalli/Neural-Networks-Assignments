{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96453 entries, 0 to 96452\n",
      "Data columns (total 12 columns):\n",
      "Formatted Date              96453 non-null object\n",
      "Summary                     96453 non-null object\n",
      "Precip Type                 95936 non-null object\n",
      "Temperature (C)             96453 non-null float64\n",
      "Apparent Temperature (C)    96453 non-null float64\n",
      "Humidity                    96453 non-null float64\n",
      "Wind Speed (km/h)           96453 non-null float64\n",
      "Wind Bearing (degrees)      96453 non-null float64\n",
      "Visibility (km)             96453 non-null float64\n",
      "Loud Cover                  96453 non-null float64\n",
      "Pressure (millibars)        96453 non-null float64\n",
      "Daily Summary               96453 non-null object\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/vlith/OneDrive/Documents/Downloads/weatherHistory.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def normalize(data):\n",
    "    data_mean = data.mean(axis=0)\n",
    "    data_std = data.std(axis=0)\n",
    "    return (data - data_mean) / data_std\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split the dataset into training and testing parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "def build_lstm_model(input_shape, num_layers, units_per_layer, dropout_rate):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adding the first LSTM layer\n",
    "    model.add(LSTM(units=units_per_layer[0], return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Adding subsequent LSTM layers\n",
    "    for i in range(1, num_layers):\n",
    "        # Return sequences for all layers except the last one\n",
    "        return_sequences = True if i < num_layers - 1 else False\n",
    "        model.add(LSTM(units=units_per_layer[i], return_sequences=return_sequences))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid'))  # Adjust units and activation function based on the task\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_shape = (data)  # Define your input shape\n",
    "num_layers = 3  # Number of LSTM layers\n",
    "units_per_layer = [64, 64, 64]  # Number of units in each LSTM layer\n",
    "dropout_rate = 0.2  # Dropout rate to prevent overfitting\n",
    "\n",
    "model = build_lstm_model(input_shape, num_layers, units_per_layer, dropout_rate)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(), metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
